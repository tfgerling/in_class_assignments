{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63e72d9d",
   "metadata": {},
   "source": [
    "1. Write simple (straightforward) definitions for the following parameters for RandomForestClassifier\n",
    "(https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and indicate how they correlate with the precision and recall for the basic diabetes model we built in class. You will need to rerun the model multiple times to do so.\n",
    "\n",
    "Parameter Correlation with Precision Correlation with Recall\n",
    "- estimators - the number of trees you want the algorithm to create (default is 100)\n",
    "- max_depth - the measure of how much further the tree has to be expanded down to each node until we get to the leaf node (default is None). \n",
    "- min_samples_split - the minimum number of working set size at node required to split (default=2). This tells the tree not to split at a node unless there are at least min_sample_split samples.\n",
    "- min_samples_leaf - The minimum number of samples required to be at a leaf node (default=1). A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression. Increasing this number can cause underfitting.\n",
    "- min_weight_fraction_leaf - The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided. (default=0.0)\n",
    "- max_leaf_nodes - grow trees with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity.\n",
    "- min_impurity_decrease - node will be split if this split induces a decrease of the impurity greater than or equal to this value.\n",
    "- min_impurity_split - no longer exists\n",
    "\n",
    "Parameter | Adjustment made | Recall impact | Precision impact\n",
    ":---|:---|:---|:---\n",
    "estimators | used values 100, 200, 500, and 800. Precision and recall pretty much moved together with 500 having the best results early on in the homework. |  Recall was the lowest at 100, jumped up .04 at 200, stayed the same at 500, and decreased by .01 at 800. | Precision was the lowest at 100 as well, jumped up .02 at 200, .01 at 500 and decreased by .01 at 800.\n",
    "max_depth | used a number of values (2, 5, 10, 20, 50, 100, 200, 250, and 500). Precision and recall moved in opposite directions for the smaller max_depth values but were the same for 20 – 500. | Recall was lowest at 2, increased .13 at 5, increased .04 at 10 and reached best value at 20 (increasing another .04). | Precision starting the highest at 2, decreased by .07 at 5, increased .03 at 10 and increased another .01 at 20.\n",
    "min_samples_split | used values 100,50,10,5,2,0.2 and 0.5 since this one could be an int or a float. Precision and recall moved in opposite directions at the \"ends\" of my range of numbers. | Recall was lowest at 0.5 and highest at 2. Recall increased by .04 between 100 and 50, by .02 between 50 and 10, by .03 between 10 and 5 and by .01 between 5 and 2.  Between 2 and 0.2, it decreased by .11 and significantly dropped between 0.2 and 0.5 (by .28). | Precision dropped by .02 between 100 and 50, increased by .01 between 50 and 10, 10 and 5, 5 and 2, as well as between 2 and 0.2. It had it's largest jump between 0.2 and 0.5 (.22) while recall dropped the most at this time.\n",
    "min_samples_leaf | used values 50, 30, 20, 5, 2, and 1. Precision and recall moved in the opposite direction for the larger numbers (50, 30, 20) and in the same direction for the smaller numbers (5, 2, 1). The best value for both ended up being the default of 1. | . Recall increasing from each number in my series (.42 at 50 and .58 at 1). | Precision dropped from .72 at 50 to .27 at 20 before heading back up, ending at .71 at 1.\n",
    "min_weight_fraction_leaf |used a lot of small numbers here – 0.05, 0.04, 0.03, 0.02, 0.01, 0.005, 0.001, 0.003 and 0.0. Precision and recall didn't move together or opposite in any pattern on this one. |The values of 0.001 and 0.0 (default) had the same results.|The values of 0.001 and 0.0 (default) had the same results.\n",
    "max_leaf_nodes | used values 2, 5, 10, 20, 100, 250, 500, and None (default). Precision and recall moved in the opposite direction for 2, 5, and 10 and moved together or had no net change for the rest of the numbers. | Since both moved up by .01 between 500 and None, None was the end resulting choice.| Since both moved up by .01 between 500 and None, None was the end resulting choice.\n",
    "min_impurity_decrease | used values 0.03, 0.02, 0.01, 0.1, 0.001, 0.003 and 0.0. First off, 0.1 resulted in both being 0 as it gave a warning. For the first 3 values, precision and recall moved in opposite directions. | Recall increased by .11 from 0.01 to 0.001, decreased by .03 between 0.001 and 0.003 and increased by .04 between 0.003 and 0.0. | Precision stayed the same from 0.01 to 0.001, decreased by .03 between 0.001 and 0.003 and increased by .03 between 0.003 and 0.0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "26427f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report, plot_confusion_matrix, precision_score, recall_score\n",
    "\n",
    "diabetes_df = pd.read_csv(\"../../in_class/in_class_assignments/diabetes.csv\")\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b03d5ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = diabetes_df.drop('Outcome', axis=1)\n",
    "y = diabetes_df['Outcome']\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42, stratify=y)\n",
    "\n",
    "#Standardize\n",
    "sc= StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65d86a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7662337662337663"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#estimator = model\n",
    "rf = RandomForestClassifier(n_estimators=200,random_state=42)\n",
    "\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e5dac86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83       150\n",
      "           1       0.70      0.58      0.64        81\n",
      "\n",
      "    accuracy                           0.77       231\n",
      "   macro avg       0.75      0.72      0.73       231\n",
      "weighted avg       0.76      0.77      0.76       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = rf.predict(X_test)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "31de23f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision for estimate  100 is 0.68\n",
      "recall for estimate  100 is 0.54\n",
      "precision for estimate  200 is 0.7\n",
      "recall for estimate  200 is 0.58\n",
      "precision for estimate  500 is 0.71\n",
      "recall for estimate  500 is 0.58\n",
      "precision for estimate  800 is 0.7\n",
      "recall for estimate  800 is 0.57\n"
     ]
    }
   ],
   "source": [
    "# writing a function and printing just recall and precision scores for each added parameter\n",
    "\n",
    "def n_est(n):\n",
    "    rf = RandomForestClassifier(n_estimators=n,random_state=42)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "    print('precision for estimate ', n, 'is', precision_score(y_test,predictions).round(2))\n",
    "    print('recall for estimate ', n, 'is', recall_score(y_test,predictions).round(2))\n",
    "    \n",
    "n_est(100)\n",
    "n_est(200)\n",
    "n_est(500)\n",
    "n_est(800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c1c3c81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision for max_depth  2 is 0.74\n",
      "recall for max_depth  2 is 0.38\n",
      "precision for max_depth  5 is 0.67\n",
      "recall for max_depth  5 is 0.51\n",
      "precision for max_depth  10 is 0.7\n",
      "recall for max_depth  10 is 0.54\n",
      "precision for max_depth  20 is 0.71\n",
      "recall for max_depth  20 is 0.58\n",
      "precision for max_depth  50 is 0.71\n",
      "recall for max_depth  50 is 0.58\n",
      "precision for max_depth  100 is 0.71\n",
      "recall for max_depth  100 is 0.58\n",
      "precision for max_depth  200 is 0.71\n",
      "recall for max_depth  200 is 0.58\n",
      "precision for max_depth  250 is 0.71\n",
      "recall for max_depth  250 is 0.58\n",
      "precision for max_depth  500 is 0.71\n",
      "recall for max_depth  500 is 0.58\n"
     ]
    }
   ],
   "source": [
    "# max_depth function\n",
    "def max_d(d):\n",
    "    rf = RandomForestClassifier(n_estimators=500,\n",
    "                                max_depth=d,\n",
    "                                random_state=42)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "    print('precision for max_depth ', d, 'is', precision_score(y_test,predictions).round(2))\n",
    "    print('recall for max_depth ', d, 'is', recall_score(y_test,predictions).round(2))\n",
    "    \n",
    "max_d(2)\n",
    "max_d(5)\n",
    "max_d(10)\n",
    "max_d(20)\n",
    "max_d(50)\n",
    "max_d(100)\n",
    "max_d(200)\n",
    "max_d(250)\n",
    "max_d(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9eb2c439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision for min_samples_split  100 is 0.7\n",
      "recall for min_samples_split  100 is 0.48\n",
      "precision for min_samples_split  50 is 0.68\n",
      "recall for min_samples_split  50 is 0.52\n",
      "precision for min_samples_split  10 is 0.69\n",
      "recall for min_samples_split  10 is 0.54\n",
      "precision for min_samples_split  5 is 0.7\n",
      "recall for min_samples_split  5 is 0.57\n",
      "precision for min_samples_split  2 is 0.71\n",
      "recall for min_samples_split  2 is 0.58\n",
      "precision for min_samples_split  0.2 is 0.72\n",
      "recall for min_samples_split  0.2 is 0.47\n",
      "precision for min_samples_split  0.5 is 0.94\n",
      "recall for min_samples_split  0.5 is 0.19\n"
     ]
    }
   ],
   "source": [
    "#performed the same with max_depth of 20, 50, 100, 200, 250, and 500. Will stay with 20\n",
    "def min_sam(s):\n",
    "    rf = RandomForestClassifier(n_estimators=500,\n",
    "                                max_depth=20,\n",
    "                                min_samples_split=s,\n",
    "                                random_state=42)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "    print('precision for min_samples_split ', s, 'is', precision_score(y_test,predictions).round(2))\n",
    "    print('recall for min_samples_split ', s, 'is', recall_score(y_test,predictions).round(2))\n",
    "    \n",
    "min_sam(100)\n",
    "min_sam(50)\n",
    "min_sam(10)\n",
    "min_sam(5)\n",
    "min_sam(2)\n",
    "min_sam(0.2)\n",
    "min_sam(0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "4a073647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision for min_samples_leaf  50 is 0.72\n",
      "recall for min_samples_leaf  50 is 0.42\n",
      "precision for min_samples_leaf  30 is 0.69\n",
      "recall for min_samples_leaf  30 is 0.46\n",
      "precision for min_samples_leaf  20 is 0.67\n",
      "recall for min_samples_leaf  20 is 0.47\n",
      "precision for min_samples_leaf  5 is 0.69\n",
      "recall for min_samples_leaf  5 is 0.54\n",
      "precision for min_samples_leaf  2 is 0.69\n",
      "recall for min_samples_leaf  2 is 0.56\n",
      "precision for min_samples_leaf  1 is 0.71\n",
      "recall for min_samples_leaf  1 is 0.58\n"
     ]
    }
   ],
   "source": [
    "#min_samples_leaf \n",
    "def min_sam_leaf(l):\n",
    "    rf = RandomForestClassifier(n_estimators=500,\n",
    "                                max_depth=20,\n",
    "                                min_samples_split=2,\n",
    "                                min_samples_leaf=l,\n",
    "                                random_state=42)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "    print('precision for min_samples_leaf ', l, 'is', precision_score(y_test,predictions).round(2))\n",
    "    print('recall for min_samples_leaf ', l, 'is', recall_score(y_test,predictions).round(2))\n",
    "    \n",
    "min_sam_leaf(50)\n",
    "min_sam_leaf(30)\n",
    "min_sam_leaf(20)\n",
    "min_sam_leaf(5)\n",
    "min_sam_leaf(2)\n",
    "min_sam_leaf(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8fd6c3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision for min_weight_fraction_leaf  0.05 is 0.67\n",
      "recall for min_weight_fraction_leaf  0.05 is 0.47\n",
      "precision for min_weight_fraction_leaf  0.04 is 0.66\n",
      "recall for min_weight_fraction_leaf  0.04 is 0.48\n",
      "precision for min_weight_fraction_leaf  0.03 is 0.67\n",
      "recall for min_weight_fraction_leaf  0.03 is 0.49\n",
      "precision for min_weight_fraction_leaf  0.02 is 0.68\n",
      "recall for min_weight_fraction_leaf  0.02 is 0.52\n",
      "precision for min_weight_fraction_leaf  0.01 is 0.69\n",
      "recall for min_weight_fraction_leaf  0.01 is 0.56\n",
      "precision for min_weight_fraction_leaf  0.005 is 0.7\n",
      "recall for min_weight_fraction_leaf  0.005 is 0.54\n",
      "precision for min_weight_fraction_leaf  0.001 is 0.71\n",
      "recall for min_weight_fraction_leaf  0.001 is 0.58\n",
      "precision for min_weight_fraction_leaf  0.003 is 0.7\n",
      "recall for min_weight_fraction_leaf  0.003 is 0.54\n",
      "precision for min_weight_fraction_leaf  0.0 is 0.71\n",
      "recall for min_weight_fraction_leaf  0.0 is 0.58\n"
     ]
    }
   ],
   "source": [
    "# min_weight_fraction_leaf - default is 0.0\n",
    "def min_weight(w):\n",
    "    rf = RandomForestClassifier(n_estimators=500,\n",
    "                                max_depth=20,\n",
    "                                min_samples_split=2,\n",
    "                                min_samples_leaf=1,\n",
    "                                min_weight_fraction_leaf=w,\n",
    "                                random_state=42)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "    print('precision for min_weight_fraction_leaf ', w, 'is', precision_score(y_test,predictions).round(2))\n",
    "    print('recall for min_weight_fraction_leaf ', w, 'is', recall_score(y_test,predictions).round(2))\n",
    "    \n",
    "min_weight(0.05)\n",
    "min_weight(0.04)\n",
    "min_weight(0.03)\n",
    "min_weight(0.02)\n",
    "min_weight(0.01)\n",
    "min_weight(0.005)\n",
    "min_weight(0.001)\n",
    "min_weight(0.003)\n",
    "min_weight(0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8f79d34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision for max_leaf_nodes  2 is 0.92\n",
      "recall for max_leaf_nodes  2 is 0.14\n",
      "precision for max_leaf_nodes  5 is 0.71\n",
      "recall for max_leaf_nodes  5 is 0.44\n",
      "precision for max_leaf_nodes  10 is 0.66\n",
      "recall for max_leaf_nodes  10 is 0.48\n",
      "precision for max_leaf_nodes  20 is 0.68\n",
      "recall for max_leaf_nodes  20 is 0.52\n",
      "precision for max_leaf_nodes  100 is 0.69\n",
      "recall for max_leaf_nodes  100 is 0.57\n",
      "precision for max_leaf_nodes  250 is 0.7\n",
      "recall for max_leaf_nodes  250 is 0.57\n",
      "precision for max_leaf_nodes  500 is 0.7\n",
      "recall for max_leaf_nodes  500 is 0.57\n",
      "precision for max_leaf_nodes  None is 0.71\n",
      "recall for max_leaf_nodes  None is 0.58\n"
     ]
    }
   ],
   "source": [
    "# max_leaf_nodes\n",
    "def max_nodes(m):\n",
    "    rf = RandomForestClassifier(n_estimators=500,\n",
    "                                max_depth=20,\n",
    "                                min_samples_split=2,\n",
    "                                min_samples_leaf=1,\n",
    "                                min_weight_fraction_leaf=0.001,\n",
    "                                max_leaf_nodes=m,\n",
    "                                random_state=42)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "    print('precision for max_leaf_nodes ', m, 'is', precision_score(y_test,predictions).round(2))\n",
    "    print('recall for max_leaf_nodes ', m, 'is', recall_score(y_test,predictions).round(2))\n",
    "\n",
    "max_nodes(2)\n",
    "max_nodes(5)\n",
    "max_nodes(10)\n",
    "max_nodes(20)\n",
    "max_nodes(100)\n",
    "max_nodes(250)\n",
    "max_nodes(500)\n",
    "max_nodes(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "db982b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision for min_impurity_decrease  0.03 is 0.81\n",
      "recall for min_impurity_decrease  0.03 is 0.27\n",
      "precision for min_impurity_decrease  0.02 is 0.75\n",
      "recall for min_impurity_decrease  0.02 is 0.37\n",
      "precision for min_impurity_decrease  0.01 is 0.71\n",
      "recall for min_impurity_decrease  0.01 is 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision for min_impurity_decrease  0.1 is 0.0\n",
      "recall for min_impurity_decrease  0.1 is 0.0\n",
      "precision for min_impurity_decrease  0.001 is 0.71\n",
      "recall for min_impurity_decrease  0.001 is 0.57\n",
      "precision for min_impurity_decrease  0.003 is 0.68\n",
      "recall for min_impurity_decrease  0.003 is 0.54\n",
      "precision for min_impurity_decrease  0.0 is 0.71\n",
      "recall for min_impurity_decrease  0.0 is 0.58\n"
     ]
    }
   ],
   "source": [
    "# looks like none is the best for max_leaf_nodes, which is the default. min_impurity_decrease, default 0.0\n",
    "def min_imp(i):\n",
    "    rf = RandomForestClassifier(n_estimators=500,\n",
    "                                max_depth=20,\n",
    "                                min_samples_split=2,\n",
    "                                min_samples_leaf=1,\n",
    "                                min_weight_fraction_leaf=0.001,\n",
    "                                max_leaf_nodes=None,\n",
    "                                min_impurity_decrease=i,\n",
    "                                random_state=42)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "    print('precision for min_impurity_decrease ', i, 'is', precision_score(y_test,predictions).round(2))\n",
    "    print('recall for min_impurity_decrease ', i, 'is', recall_score(y_test,predictions).round(2))\n",
    "    \n",
    "min_imp(0.03)\n",
    "min_imp(0.02)\n",
    "min_imp(0.01)\n",
    "min_imp(0.1)\n",
    "min_imp(0.001)\n",
    "min_imp(0.003)\n",
    "min_imp(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f1398aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision is 0.71\n",
      "recall is 0.58\n"
     ]
    }
   ],
   "source": [
    "## everything I've chosen for the best precision/recall combo (.71/.58)\n",
    "rf = RandomForestClassifier(n_estimators=500,\n",
    "                                max_depth=20,\n",
    "                                min_samples_split=2,\n",
    "                                min_samples_leaf=1,\n",
    "                                min_weight_fraction_leaf=0.001,\n",
    "                                max_leaf_nodes=None,\n",
    "                                min_impurity_decrease=0.0,\n",
    "                                random_state=42)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "predictions = rf.predict(X_test)\n",
    "print('precision is', precision_score(y_test,predictions).round(2))\n",
    "print('recall is', recall_score(y_test,predictions).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "f885f627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision is 0.71\n",
      "recall is 0.59\n"
     ]
    }
   ],
   "source": [
    "## adjusting again\n",
    "rf = RandomForestClassifier(n_estimators=200,\n",
    "                                max_depth=20,\n",
    "                                min_samples_split=2,\n",
    "                                min_samples_leaf=1,\n",
    "                                min_weight_fraction_leaf=0.001,\n",
    "                                max_leaf_nodes=None,\n",
    "                                min_impurity_decrease=0.0,\n",
    "                                random_state=42)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "predictions = rf.predict(X_test)\n",
    "print('precision is', precision_score(y_test,predictions).round(2))\n",
    "print('recall is', recall_score(y_test,predictions).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "f75fad19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision for estimate  100 is 0.68\n",
      "recall for estimate  100 is 0.54\n",
      "precision for estimate  200 is 0.71\n",
      "recall for estimate  200 is 0.59\n",
      "precision for estimate  250 is 0.7\n",
      "recall for estimate  250 is 0.57\n",
      "precision for estimate  500 is 0.71\n",
      "recall for estimate  500 is 0.58\n",
      "precision for estimate  800 is 0.7\n",
      "recall for estimate  800 is 0.57\n"
     ]
    }
   ],
   "source": [
    "# running some of the earlier functions again with the additional values added later on since some of the earlier ones\n",
    "# had multiple values with the same precision and recall\n",
    "def n_est(n):\n",
    "    rf = RandomForestClassifier(n_estimators=n,\n",
    "                                max_depth=20,\n",
    "                                min_samples_split=2,\n",
    "                                min_samples_leaf=1,\n",
    "                                min_weight_fraction_leaf=0.001,\n",
    "                                max_leaf_nodes=None,\n",
    "                                min_impurity_decrease=0.0,\n",
    "                                random_state=42)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "    print('precision for estimate ', n, 'is', precision_score(y_test,predictions).round(2))\n",
    "    print('recall for estimate ', n, 'is', recall_score(y_test,predictions).round(2))\n",
    "    \n",
    "n_est(100)\n",
    "n_est(200)\n",
    "n_est(250)\n",
    "n_est(500)\n",
    "n_est(800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "683c05ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision for max_depth  2 is 0.74\n",
      "recall for max_depth  2 is 0.38\n",
      "precision for max_depth  5 is 0.69\n",
      "recall for max_depth  5 is 0.52\n",
      "precision for max_depth  10 is 0.68\n",
      "recall for max_depth  10 is 0.54\n",
      "precision for max_depth  20 is 0.71\n",
      "recall for max_depth  20 is 0.59\n",
      "precision for max_depth  50 is 0.7\n",
      "recall for max_depth  50 is 0.58\n",
      "precision for max_depth  100 is 0.7\n",
      "recall for max_depth  100 is 0.58\n",
      "precision for max_depth  200 is 0.7\n",
      "recall for max_depth  200 is 0.58\n",
      "precision for max_depth  250 is 0.7\n",
      "recall for max_depth  250 is 0.58\n",
      "precision for max_depth  500 is 0.7\n",
      "recall for max_depth  500 is 0.58\n"
     ]
    }
   ],
   "source": [
    "# max_depth function\n",
    "def max_d(d):\n",
    "    rf = RandomForestClassifier(n_estimators=200,\n",
    "                                max_depth=d,\n",
    "                                min_samples_split=2,\n",
    "                                min_samples_leaf=1,\n",
    "                                min_weight_fraction_leaf=0.001,\n",
    "                                max_leaf_nodes=None,\n",
    "                                min_impurity_decrease=0.0,\n",
    "                                random_state=42)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "    print('precision for max_depth ', d, 'is', precision_score(y_test,predictions).round(2))\n",
    "    print('recall for max_depth ', d, 'is', recall_score(y_test,predictions).round(2))\n",
    "    \n",
    "max_d(2)\n",
    "max_d(5)\n",
    "max_d(10)\n",
    "max_d(20)\n",
    "max_d(50)\n",
    "max_d(100)\n",
    "max_d(200)\n",
    "max_d(250)\n",
    "max_d(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "8206427a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision for min_samples_split  100 is 0.7\n",
      "recall for min_samples_split  100 is 0.48\n",
      "precision for min_samples_split  50 is 0.67\n",
      "recall for min_samples_split  50 is 0.52\n",
      "precision for min_samples_split  10 is 0.68\n",
      "recall for min_samples_split  10 is 0.56\n",
      "precision for min_samples_split  5 is 0.71\n",
      "recall for min_samples_split  5 is 0.57\n",
      "precision for min_samples_split  2 is 0.71\n",
      "recall for min_samples_split  2 is 0.59\n",
      "precision for min_samples_split  0.2 is 0.7\n",
      "recall for min_samples_split  0.2 is 0.47\n",
      "precision for min_samples_split  0.5 is 0.86\n",
      "recall for min_samples_split  0.5 is 0.22\n"
     ]
    }
   ],
   "source": [
    "def min_sam(s):\n",
    "    rf = RandomForestClassifier(n_estimators=200,\n",
    "                                max_depth=20,\n",
    "                                min_samples_split=s,\n",
    "                                min_samples_leaf=1,\n",
    "                                min_weight_fraction_leaf=0.001,\n",
    "                                max_leaf_nodes=None,\n",
    "                                min_impurity_decrease=0.0,\n",
    "                                random_state=42)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "    print('precision for min_samples_split ', s, 'is', precision_score(y_test,predictions).round(2))\n",
    "    print('recall for min_samples_split ', s, 'is', recall_score(y_test,predictions).round(2))\n",
    "    \n",
    "min_sam(100)\n",
    "min_sam(50)\n",
    "min_sam(10)\n",
    "min_sam(5)\n",
    "min_sam(2)\n",
    "min_sam(0.2)\n",
    "min_sam(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "d9c0e3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision is 0.71\n",
      "recall is 0.59\n"
     ]
    }
   ],
   "source": [
    "# got recall to increase by .01 by changing the n_estimators from 500 to 200\n",
    "rf = RandomForestClassifier(n_estimators=200,\n",
    "                                max_depth=20,\n",
    "                                min_samples_split=2,\n",
    "                                min_samples_leaf=1,\n",
    "                                min_weight_fraction_leaf=0.001,\n",
    "                                max_leaf_nodes=None,\n",
    "                                min_impurity_decrease=0.0,\n",
    "                                random_state=42)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "predictions = rf.predict(X_test)\n",
    "print('precision is', precision_score(y_test,predictions).round(2))\n",
    "print('recall is', recall_score(y_test,predictions).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03245ea6",
   "metadata": {},
   "source": [
    "2. How does setting bootstrap=False influence the model performance? Note: the default is bootstrap=True. Explain why your results might be so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204913f4",
   "metadata": {},
   "source": [
    "bootstrap : bool, default=True indicates whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "c2ca51bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision is 0.71\n",
      "recall is 0.59\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200,\n",
    "                                max_depth=20,\n",
    "                                min_samples_split=2,\n",
    "                                min_samples_leaf=1,\n",
    "                                min_weight_fraction_leaf=0.001,\n",
    "                                max_leaf_nodes=None,\n",
    "                                min_impurity_decrease=0.0,\n",
    "                                bootstrap=False,\n",
    "                                random_state=42)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "predictions = rf.predict(X_test)\n",
    "print('precision is', precision_score(y_test,predictions).round(2))\n",
    "print('recall is', recall_score(y_test,predictions).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c200811",
   "metadata": {},
   "source": [
    "Using bootstrap=False had no impact on the results. I'm thinking it is because max_samples parameter wasn't used so the whole dataset was used, which is what bootstrap=False also does for you. Adding in max_samples with bootstrap=True then False to see if I'm on the right track. It appears that using the whole dataset has better recall and precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "f080da1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision is 0.7\n",
      "recall is 0.57\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200,\n",
    "                                max_depth=20,\n",
    "                                min_samples_split=2,\n",
    "                                min_samples_leaf=1,\n",
    "                                min_weight_fraction_leaf=0.001,\n",
    "                                max_leaf_nodes=None,\n",
    "                                min_impurity_decrease=0.0,\n",
    "                                max_samples=500,\n",
    "                                bootstrap=True,\n",
    "                                random_state=42)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "predictions = rf.predict(X_test)\n",
    "print('precision is', precision_score(y_test,predictions).round(2))\n",
    "print('recall is', recall_score(y_test,predictions).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "ce585bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision is 0.71\n",
      "recall is 0.59\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200,\n",
    "                                max_depth=20,\n",
    "                                min_samples_split=2,\n",
    "                                min_samples_leaf=1,\n",
    "                                min_weight_fraction_leaf=0.001,\n",
    "                                max_leaf_nodes=None,\n",
    "                                min_impurity_decrease=0.0,\n",
    "                                max_samples=500,\n",
    "                                bootstrap=False,\n",
    "                                random_state=42)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "predictions = rf.predict(X_test)\n",
    "print('precision is', precision_score(y_test,predictions).round(2))\n",
    "print('recall is', recall_score(y_test,predictions).round(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
