{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d703fbbf",
   "metadata": {},
   "source": [
    "## Week 18 in class assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92630f1",
   "metadata": {},
   "source": [
    "### 1. Look up the Adam optimization functions in PyTorch https://pytorch.org/docs/stable/optim.html . \n",
    "\n",
    "How does it work? Try at least one other optimization function with the diabetes dataset shown in class. \n",
    "\n",
    "How does the model perform with the new optimizer? \n",
    "\n",
    "Did it perform better or worse than Adam? Why do you think that is?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8d02af",
   "metadata": {},
   "source": [
    "Adam optimization - algorithm on top of Base class. Adam optimizer involves a combination of two gradient descent methodologies - momentum (taking into consideration the exponentially weighted average of the gradients) and Root mean square propagation  (taking the exponential moving average).\n",
    "\n",
    "Similar to the momentum optimizer, Adam makes use of an exponentially decaying average of past gradients. Thus, the direction of parameter updates is calculated in a manner similar to that of the momentum optimizer.\n",
    "\n",
    "Adam also employs an exponentially decaying average of past squared gradients in order to provide an adaptive learning rate. Thus, the scale of the learning rate for each dimension is calculated in a manner similar to that of the RMSProp optimizer.\n",
    "\n",
    "Changed the learning rate to 0.05 and increase recall, precision, and accuracy.\n",
    "\n",
    "Chose Adagrad which performed slightly better than Adam, with the same parameters. I think it is because with Adagrad, each parameter has it's own learning rate that improves performance with sparse gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63fb0739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "diabetes_df = pd.read_csv(\"../../in_class/in_class_assignments/diabetes.csv\")\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d0b99b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = diabetes_df.drop('Outcome', axis=1).values\n",
    "y = diabetes_df['Outcome'].values\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Standardize\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "336ee1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F #where the activation functions are\n",
    "\n",
    "#create tensors = matrices\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a6f0f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#artificial neural network\n",
    "class ANN_Model(nn.Module):\n",
    "    def __init__(self, input_features=8,hidden1=20,hidden2=20,out_features=2):\n",
    "        super().__init__() #super is a computed indirect reference. So, it isolates changes\n",
    "        # and makes sure that children in the layers of multiple inheritence are calling\n",
    "        #the right parents\n",
    "        self.layer_1_connection = nn.Linear(input_features, hidden1)\n",
    "        self.layer_2_connection = nn.Linear(hidden1, hidden2)\n",
    "        self.out = nn.Linear(hidden2, out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #apply activation functions\n",
    "        x = F.relu(self.layer_1_connection(x))\n",
    "        x = F.relu(self.layer_2_connection(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7255f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "#create instance of model\n",
    "ann = ANN_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67b210fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer\n",
    "optimizer = torch.optim.Adam(ann.parameters(),lr=0.01) #lr is learning rate - play around with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23690e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 1 with loss: 0.647470235824585\n",
      "Epoch number: 11 with loss: 0.5270779132843018\n",
      "Epoch number: 21 with loss: 0.4539138376712799\n",
      "Epoch number: 31 with loss: 0.4234801232814789\n",
      "Epoch number: 41 with loss: 0.39819812774658203\n",
      "Epoch number: 51 with loss: 0.3721073269844055\n",
      "Epoch number: 61 with loss: 0.34377244114875793\n",
      "Epoch number: 71 with loss: 0.31378453969955444\n",
      "Epoch number: 81 with loss: 0.28582650423049927\n",
      "Epoch number: 91 with loss: 0.25994443893432617\n",
      "Epoch number: 101 with loss: 0.2377132922410965\n",
      "Epoch number: 111 with loss: 0.21422427892684937\n",
      "Epoch number: 121 with loss: 0.19071193039417267\n",
      "Epoch number: 131 with loss: 0.17592686414718628\n",
      "Epoch number: 141 with loss: 0.15840402245521545\n",
      "Epoch number: 151 with loss: 0.14416663348674774\n",
      "Epoch number: 161 with loss: 0.12847739458084106\n",
      "Epoch number: 171 with loss: 0.11511365324258804\n",
      "Epoch number: 181 with loss: 0.10320579260587692\n",
      "Epoch number: 191 with loss: 0.09023238718509674\n",
      "Epoch number: 201 with loss: 0.07916071265935898\n",
      "Epoch number: 211 with loss: 0.0684264600276947\n",
      "Epoch number: 221 with loss: 0.059748344123363495\n",
      "Epoch number: 231 with loss: 0.05305880308151245\n",
      "Epoch number: 241 with loss: 0.04553648456931114\n",
      "Epoch number: 251 with loss: 0.03982141613960266\n",
      "Epoch number: 261 with loss: 0.03491397947072983\n",
      "Epoch number: 271 with loss: 0.03038678504526615\n",
      "Epoch number: 281 with loss: 0.02632552571594715\n",
      "Epoch number: 291 with loss: 0.022437868639826775\n",
      "Epoch number: 301 with loss: 0.01941421627998352\n",
      "Epoch number: 311 with loss: 0.01703641749918461\n",
      "Epoch number: 321 with loss: 0.015042798593640327\n",
      "Epoch number: 331 with loss: 0.013381404802203178\n",
      "Epoch number: 341 with loss: 0.011985255405306816\n",
      "Epoch number: 351 with loss: 0.010780823417007923\n",
      "Epoch number: 361 with loss: 0.009726954624056816\n",
      "Epoch number: 371 with loss: 0.008817268535494804\n",
      "Epoch number: 381 with loss: 0.008032923564314842\n",
      "Epoch number: 391 with loss: 0.007309386506676674\n",
      "Epoch number: 401 with loss: 0.0066734482534229755\n",
      "Epoch number: 411 with loss: 0.006115449592471123\n",
      "Epoch number: 421 with loss: 0.005624391138553619\n",
      "Epoch number: 431 with loss: 0.005159178748726845\n",
      "Epoch number: 441 with loss: 0.004757321439683437\n",
      "Epoch number: 451 with loss: 0.0043939827010035515\n",
      "Epoch number: 461 with loss: 0.0040780408307909966\n",
      "Epoch number: 471 with loss: 0.0037870127707719803\n",
      "Epoch number: 481 with loss: 0.0035326173529028893\n",
      "Epoch number: 491 with loss: 0.003304499899968505\n"
     ]
    }
   ],
   "source": [
    "#run model through multiple epochs/iterations\n",
    "final_loss = []\n",
    "n_epochs = 500\n",
    "for epoch in range(n_epochs):\n",
    "    y_pred = ann.forward(X_train)\n",
    "    loss = loss_function(y_pred, y_train)\n",
    "    final_loss.append(loss)\n",
    "    \n",
    "    if epoch % 10 == 1:\n",
    "        print(f'Epoch number: {epoch} with loss: {loss}')\n",
    "        \n",
    "    optimizer.zero_grad() #zero the gradient before running backwards propagation\n",
    "    loss.backward() \n",
    "    optimizer.step() #perform one optimization step each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52eba8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test):\n",
    "        prediction = ann(data)\n",
    "        y_pred.append(prediction.argmax())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7685e355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78       150\n",
      "           1       0.59      0.49      0.54        81\n",
      "\n",
      "    accuracy                           0.70       231\n",
      "   macro avg       0.67      0.65      0.66       231\n",
      "weighted avg       0.69      0.70      0.69       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d97b89d",
   "metadata": {},
   "source": [
    "Going to work on the learning rate first (leaving Adam there) to see what the results are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8d5bea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer\n",
    "optimizer = torch.optim.Adam(ann.parameters(),lr=0.05) #lr is learning rate - play around with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7902ed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run model through multiple epochs/iterations\n",
    "final_loss = []\n",
    "n_epochs = 500\n",
    "for epoch in range(n_epochs):\n",
    "    y_pred = ann.forward(X_train)\n",
    "    loss = loss_function(y_pred, y_train)\n",
    "    final_loss.append(loss)\n",
    "    \n",
    "    optimizer.zero_grad() #zero the gradient before running backwards propagation\n",
    "    loss.backward() \n",
    "    optimizer.step() #perform one optimization step each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d976bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test):\n",
    "        prediction = ann(data)\n",
    "        y_pred.append(prediction.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e18baa33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.80       150\n",
      "           1       0.62      0.56      0.59        81\n",
      "\n",
      "    accuracy                           0.73       231\n",
      "   macro avg       0.70      0.69      0.69       231\n",
      "weighted avg       0.72      0.73      0.72       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "953549f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer\n",
    "optimizer = torch.optim.Adagrad(ann.parameters(),lr=0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "41aa9eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run model through multiple epochs/iterations\n",
    "final_loss = []\n",
    "n_epochs = 500\n",
    "for epoch in range(n_epochs):\n",
    "    y_pred = ann.forward(X_train)\n",
    "    loss = loss_function(y_pred, y_train)\n",
    "    final_loss.append(loss)\n",
    "    \n",
    "    optimizer.zero_grad() #zero the gradient before running backwards propagation\n",
    "    loss.backward() \n",
    "    optimizer.step() #perform one optimization step each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "74726628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test):\n",
    "        prediction = ann(data)\n",
    "        y_pred.append(prediction.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4da2af9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79       150\n",
      "           1       0.60      0.51      0.55        81\n",
      "\n",
      "    accuracy                           0.71       231\n",
      "   macro avg       0.68      0.66      0.67       231\n",
      "weighted avg       0.70      0.71      0.70       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b97935",
   "metadata": {},
   "source": [
    "### 2. Write a function that lists and counts the number of divisors for an input value.\n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: 5\n",
    "\n",
    "Output: “There are 2 divisors: 1 and 5”\n",
    "\n",
    "Example 2:\n",
    "\n",
    "Input: 40\n",
    "\n",
    "Output: “There are 8 divisors: 1, 2, 4, 5, 8, 10, 20, and 40\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4da3b3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divisor_count(num):\n",
    "    divisors = []\n",
    "    for i in range(1, num + 1):\n",
    "        if num % i == 0:\n",
    "            divisors.append(i)\n",
    "    #convert to string, putting all but the last number into the string so a comma can be added if needed\n",
    "    str_to_hold = str((divisors)[:-1])[1:-1]\n",
    "    #if the string is longer than 1 digit, adding a comma at the end\n",
    "    if len(str_to_hold) > 1:\n",
    "        str_to_hold = str_to_hold + ','\n",
    "    #using the converted string, print it followed by \"and\" and then the last one   \n",
    "    print(f'There are {len(divisors)} divisors: {str_to_hold} and {divisors[-1]}')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "67b7a25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 divisors: 1 and 5\n",
      "There are 8 divisors: 1, 2, 4, 5, 8, 10, 20, and 40\n"
     ]
    }
   ],
   "source": [
    "divisor_count(5)\n",
    "divisor_count(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "16928301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 divisors: 1, 2, and 4\n"
     ]
    }
   ],
   "source": [
    "divisor_count(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9781c112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
